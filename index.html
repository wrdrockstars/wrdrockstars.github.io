Hello World


IGBP LINUX Story:

We were trying to clip nc files from a shapefile and then extract 'fSCA' (fractional snow cover area) for calculating snow covered area and save daily output file (csv). This task was accomplished using xarray, geopandas, shapely and pandas in the python programming language. Once the code was ready and running, it was found that the PC did not have enough specifications to achieve the processing of 35+ GB of data spanning 23 years. The script was prone to crashing due to low PC specs.

To overcome this problem, it was decided by Dr. Ishan Rayal (PhD, WRD, IIRS-Doon University) to use the then available Windows Server under IGBP. This server has 256 GB of RAM with 48 core Xeon processor. Miniconda was installed and attempts were made to create environments using .yaml and also manually. The envs were being created, however, while importing shapely and geopandas DLL error was persistent. One possible reason for this could be the mismatch between available python packages and the Windows server OS.

In order to circumvent this problem, our thoughtful eyes were set towards the cousin of Windows IGBP Server i.e. LINUX IGBP Server. IDs were finally created on the Linux Server, Miniconda was installed and env were created. The challenge was that the nc files were stored in a separate storage server with access to a share folder running Windows Server OS. This share folder was made to be accessible inside the Linux server. For this, a new directory was created and the shared folder was mounted to this directory using 'CIFS utils'. Generally this is installed by default in Linux sudo priveleges are required for this, alternatives are samba, smbclient, sudo priveleges were provided by Vaibhav Sir's ID. The python script was converted into a command line utility using argparse and then multiple sessions for different years were run using bash script separated by &.




The following code, which was popularly known as Udta_teer_3, was modified and added a few lines. These lines became imperative because while running the whole code the volatile memory (RAM) of the LINUX server was getting occupied (>90%) which was causing errors in the process and made the task very heavy for the system to execute. The sole reason, as we anticipated, could be the formation of unwanted cache or temporary files in the loop when it opens an NC file in data variable using xarray. So to overcome this general/popular problem of handling and processing large data files, the following few lines were added (shown separately with spaces).

        
        data.close()
        del data, clipped_data, fsca, fsca_binary
        # Explicit garbage collection
        gc.collect()
